{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pedron18/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from transformers import DecisionTransformerModel, DecisionTransformerConfig\n",
    "from time import sleep\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of model: 12.26 MB (0.01 GB)\n"
     ]
    }
   ],
   "source": [
    "max_ep_length = 11264 # maximum number that can exists in timesteps (frame number we skip 10 so this gets high)\n",
    "n_positions = 2**10 # The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).\n",
    "batch_size = 64 # The batch size to use for training.\n",
    "state_dim = (10,10,10)\n",
    "state_dim_flatten = state_dim[0]*state_dim[1]*state_dim[2]\n",
    "action_dim = 6\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "config = DecisionTransformerConfig(state_dim=state_dim_flatten, act_dim=action_dim, max_ep_len=max_ep_length, n_positions=n_positions, action_tanh=True)\n",
    "model = DecisionTransformerModel(config).to(device=device)\n",
    "\n",
    "param_size = 0\n",
    "for param in model.parameters():\n",
    "    param_size += param.nelement() * param.element_size()\n",
    "buffer_size = 0\n",
    "for buffer in model.buffers():\n",
    "    buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "size_model_mb = (param_size + buffer_size) / 1024**2\n",
    "size_model_gb = size_model_mb / 1024\n",
    "print(f\"Size of model: {size_model_mb:.2f} MB ({size_model_gb:.2f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states: torch.Size([1, 2, 1000]), actions: torch.Size([1, 2, 6]), target_return: torch.Size([1, 2, 1]), timesteps: torch.Size([1, 2])\n",
      "state_preds: torch.Size([2, 1000]), action_preds: torch.Size([2, 6]), return_preds: torch.Size([2, 1])\n",
      "pred_arr: [ 0.14693639 -0.23803829 -0.1962808  -0.10674385  0.01430107 -0.14090946],  actionIdx: 0\n"
     ]
    }
   ],
   "source": [
    "# fake data\n",
    "\n",
    "def fake_data(batch, sequence_length):\n",
    "    target_return = torch.rand((batch, sequence_length, 1), device=device, dtype=torch.float32) # expected future return\n",
    "    states = torch.rand((batch, sequence_length, state_dim_flatten), device=device, dtype=torch.float32)#.reshape(1, 1, state_dim_flatten) #\n",
    "    actions = torch.rand((batch, sequence_length, action_dim), device=device, dtype=torch.float32)\n",
    "    timesteps = torch.tensor([[i for i in range(1, sequence_length+1)] for _ in range(batch)], device=device, dtype=torch.long) # integer what timestep we on\n",
    "\n",
    "    return states, actions, target_return, timesteps\n",
    "\n",
    "\n",
    "seq = 2\n",
    "b = 1\n",
    "states, actions, target_return, timesteps = fake_data(b, seq)\n",
    "\n",
    "print(f\"states: {states.shape}, actions: {actions.shape}, target_return: {target_return.shape}, timesteps: {timesteps.shape}\")\n",
    "\n",
    "\n",
    "# foward pass\n",
    "model.eval()\n",
    "attention_mask = torch.ones((b, seq), device=device, dtype=torch.float32)\n",
    "\n",
    "state_preds, action_preds, return_preds = model(states=states,\n",
    "    actions=actions,\n",
    "    rewards=None, #not used in foward pass https://github.com/huggingface/transformers/blob/v4.27.2/src/transformers/models/decision_transformer/modeling_decision_transformer.py#L831\n",
    "    returns_to_go=target_return, # return to go is the sum of all future rewards\n",
    "    timesteps=timesteps,\n",
    "    attention_mask=attention_mask,\n",
    "    return_dict=False)\n",
    "\n",
    "# remove batch dim  \n",
    "state_preds, action_preds, return_preds = torch.squeeze(state_preds, 0), torch.squeeze(action_preds, 0), torch.squeeze(return_preds, 0)\n",
    "print(f\"state_preds: {state_preds.shape}, action_preds: {action_preds.shape}, return_preds: {return_preds.shape}\")\n",
    "\n",
    "actionIdx = torch.argmax(action_preds[-1]).item()\n",
    "pred_arr = torch.squeeze(action_preds[-1]).detach().cpu().numpy()\n",
    "print(f\"pred_arr: {pred_arr},  actionIdx: {actionIdx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5065848231315613"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, a, r, t = fake_data(64, 6)\n",
    "\n",
    "a.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[45], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m x \u001B[39m=\u001B[39m [[[\u001B[39m1\u001B[39m,\u001B[39m2\u001B[39m],[\u001B[39m3\u001B[39m,\u001B[39m4\u001B[39m]],\n\u001B[1;32m      2\u001B[0m      [[\u001B[39m5\u001B[39m,\u001B[39m6\u001B[39m],[\u001B[39m7\u001B[39m,\u001B[39m8\u001B[39m]]]\n\u001B[0;32m----> 4\u001B[0m x[:, \u001B[39m2\u001B[39;49m]\n",
      "\u001B[0;31mTypeError\u001B[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "\n",
    "#x[:, 2] # get t's for actions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
